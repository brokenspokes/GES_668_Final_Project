---
title: "GES668: Property Assessments in Baltimore"
author: "Joshua Spokes"
format: 
  revealjs:
    slide-number: true
    multiplex: true
date-modified: 2024-12-14
---


## The Data




## Working with Reveal.js

This slide includes a code block and presentation notes.

```{r}
#| label: example_code-block
#| echo: true
library(sf)
library(ggplot2)

nc <- st_read(system.file("shape/nc.shp", package="sf"))

ggplot() +
  geom_sf(data = nc, aes(fill = NAME)) +
  guides(fill = "none")
```

::: notes

This is an example of how you add in presentation notes.

:::


## Working with Reveal.js

This slide includes a hidden code block and a custom footer. See the [Quarto code cells reference](https://quarto.org/docs/reference/cells/cells-knitr.html) for more information.

```{r}
#| label: example_hidden-code-block
#| echo: false

library(dplyr)
library(gt)

nc |> 
  st_drop_geometry() |> 
  select(AREA, PERIMETER, NAME, FIPS) |> 
  slice_head(n = 3) |> 
  gt()
```

::: footer
This is an example of a custom footer.
:::


## Overview

Are certain types of properties getting a free ride on their taxes?
![Project Origin](2_block_city.png)

::: {.notes}
Back when I was first learning about data analysis, I started a project looking at assessment values in and around the Patterson Bowling Alley. I compared the property taxes being paid by the blocks in the image and found that the commercial property in the middle was paying significantly less for the same amount of land.
:::

## Project goals

1. Identify tranches of property suspected to follow this pattern (Vacant, Auto-Oriented, etc.)

2. Match these patterns to recorded sales

3. Aggregate sales data by block group

::: {.notes}
My initial goals for the project were to identify sales of property in various categories defined in the proposal, like vacant, unimproved, and auto-oriented. I then planned to compare the sale price to the assessed price for the year and aggregate the data into block groups in order to analyze the sales.

:::

## Changes in Scope

- Analysis was limited to the last five years

- Analysis limited by data quality

- Aggregation switched from census tracts to neighborhoods

::: {.notes}
As I dug into my exploratory analysis, I immediately ran into the limitation that the assessments only include the most recent years. This greatly affected my ability to look at things longitudinally. It was also hard to pluck out sales of homes that were flipped, which resulted in price to assessment ratios that were incredibly high. Finally, I found that it was easier to aggregate sales into neighborhood groups for the purposes of analysis because this provides bigger samples and better opportunities for any kind of insight.
:::


## Data sources

- Maryland CAMA/Assessment data is all public domain

- Baltimore DHCD data licensed under Creative Commons 3.0

- Baltimore Vacants data available under DOI [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14497481.svg)](https://doi.org/10.5281/zenodo.14497481)

::: {.notes}
The data used for this project come from Maryland's planning cadastre service on IMAP, with additional supporting data coming from Baltimore's open data portal and a dataset of vacant building notices provided by the Baltimore Department of Housing and Community Development. The extracts used for this analysis are all available through Zenodo
:::

## Baltimore Real Property

```{r real-prop}
#| label: baltimore-real-prop
#| include: false
library(sf)
library(tmap)
st_read("Data/baltimore_real_prop_boundaries.gpkg") -> baltimore

baltimore |>
  st_make_valid() |>
  tm_shape() +
  tm_polygons()
```

:::{.notes}
This dataset is available through the Baltimore Open Data portal, so it is easy to download 

:::


More than one slide per data source is likely required for this section and basic information on each major data source used in your project. Make sure to answer:

-   What data sources did you use?

-   How, why, and where were they created?

The data used for this project come from Maryland's planning cadastre service on IMAP, with additional supporting data coming from Baltimore's open data portal and a dataset of vacant building notices provided by the Baltimore Department of Housing and Community Development.


## Approach and methods for working with data

My project involved a significant amount of exploratory analysis, looking to determine the best ways to approach the intended goal. As I delved deeper into the project, I found that the quantity of the data or the quality of the data and transformations I was completing makes the comparisons very difficult. The results were not what I was expecting

Briefly recap related information from your initial project proposal describing your approach. Make sure to answer:

-   Did your approach involve mapping, exploratory analysis, documentation, visualization, or a combination of multiple approaches?

-   Why did you select this approach and did you change apporach while completing your final project?

-   What packages, templates, or other resources did you use in creating your final project?



## Challenges in working with data

What challenges did you encounter in making use of these resources and this data?

There are different primary keys to use between Baltimore city data and maryland state data

I frequently found myself backtracking to add attributes to various intermediate datasets



## Successes in working with data

I think my analysis does a good job in taking a very big dataset and distilling it to a more useable format. I aimed to make the data more tidy so that it would be easier to create comparisons

What do you think your project does well?

Your areas of success likely depend on your approach:

-   If you completed a data analysis, what are your key findings?

-   If you created a map, what does it communicate to people who see it?


## Where to learn more

::: {.r-fit-text}

Add links or brief descriptions of how to find the required elements for your project repository.

project data
: source files or a script used for importing and processing the data before visualization or analysis. Students who are using {osmdata} or {tidycensus} should include scripts for downloading data.

project code
: any R scripts, RMarkdown, or Quarto files used to read, tidy, transform, analyze, visualize or map the selected data.

output files
: including any processed data files or rendered PDF or HTML documents.

README
: a public-facing summary of the project explaining your process for processing the data and any relevant information another person may need to work with the data or your code.

These can be placeholder links as you still have time to complete the final project and some elements may be incomplete.

:::

::: footer

This slide uses a [fit-text div](https://quarto.org/docs/presentations/revealjs/advanced.html#fit-text) to make sure the text fits on a single slide. Learn more about [Advanced Reveal features in the Quarto documentation](https://quarto.org/docs/presentations/revealjs/advanced.html).
:::
